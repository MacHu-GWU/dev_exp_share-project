Hudi Concepts
==============================================================================


Overview
------------------------------------------------------------------------------
`Apache Hudi Concepts <https://hudi.apache.org/docs/concepts/>`_ 是 Hudi 官方介绍核心概念的文档. 里面介绍了 Time Line, File Group, Index, Copy-on-Write, Merge-on-Read, Snapshot Query, Incremental Query, Read Optimized Queries 等概念.

本文是我研读该文档自己做的总结和笔记.


Timeline
------------------------------------------------------------------------------
Hudi 依赖一个单调递增的时间戳用来标记每个 Action 的先后顺序, 并且按照一定的隔离机制, 从而实现确保 ACID 的目的.


File management
------------------------------------------------------------------------------
Hudi 在每个数据 Partition 下建立了 File Group 概念, 一个 File Group 下面会包含同一个文件的多个历史版本, 并且会设定一个最大体积或是行数的阈值, 超过这个数就新建一个, 并且在产生多个小文件时会以 File Group 为单位做 Compaction.


File Index
------------------------------------------------------------------------------
简单来说就是维护着 record_id 到 file group 的映射关系, 从而当新数据进来后, 可以快速的定位到哪些数据是 insert, 哪些是 update, 这些 update 的数据会影响到哪些文件.


Table Type
------------------------------------------------------------------------------
Hudi 支持 Copy on Write (COW) 和 Merge on Read (MOR) 两种表, 它们有着不同的读写策略. 简单来说 COW 读性能高, 写性能差. MOR 则是写性能高, 读性能差. COW 表更简单.

简单来说 COW 就是在对文件进行 update 和 insert 的时, 不修改原来的文件版本, 而是拷贝一份, 更新好了再写到新版本里, 旧版本会在 metadata 标记好, 查询最新数据的时候就会用最新的文件. 这个拷贝一份的动作则是 COW 名字的由来. 而 MOR 则是每次写入的时候不管 update 和 insert, 仅仅是把新数据当成 log 写入到一个新文件里. 在读的时候再把旧文件和 Log 文件合起来分析, 决定最新的数据应该是什么, 并且会自动 Merge (Compaction) 形成一个新的起始点, 以后新的数据再进来就可以从这个新的起始点开始追加了. 这个 Merge 也是 MOR 名字的由来.

两着比较起来:

- Data Latency:
    - COW 高, 因为要做自动 compaction.
    - MOR 低, 因为写入时只追加 Log 既可
- Update cost (I/O):
    - COW 高, 因为要重写整个文件
    - MOR 低, 因为只追加 Log
- Parquet File Size:
    - COW 小, 因为文件很紧凑
    - MOR 大, 因为每个版本都以 Log 的形式保存了
- Write Amplification:
    - COW 大, 因为如果改动涉及到所有文件, 那么相当于每写入一次就增加一次全量数据.
    - MOR 小, 不过取决于你的 compaction 策略.


Snapshot Queries
------------------------------------------------------------------------------
简单来说就是既可以查询最新数据, 也可以查询 Point-in-time 数据. COW 和 MOR 都支持这个模式.


Incremental Queries
------------------------------------------------------------------------------
只查询增量数据. 这个常用于你有一个 Batch Consumer 不断地从 Hudi 表中读增量数据的应用场景, 相当于你把 Hudi 当成了一个 Kafka Stream 来用了. 只不过普通的 Kafka Consumer 只能一次处理少量数据, 而从 Hudi 中读增量数据你一次能读大量数据. COW 和 MOR 都支持这个模式.


Read Optimized Queries
------------------------------------------------------------------------------
简单来说就是为查询最新数据所优化的一种查询. 只有 MOR 表支持, COW 表不支持 (因为 COW 本身查询最新数据的性能就很高了, 没有优化的必要)
